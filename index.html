<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dota - Tianai Dong</title>

  <meta name="author" content="Dota">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <h1>Dota - Tianai Dong</h1>
              </p>
             <p>
Hi! I am a second-year PhD student, affiliated with <a href="https://www.mpi.nl/department/multimodal-language-department/23" target="_blank"> Multimodal Language Department </a> at the Max Planck Institute for Psycholinguistics, and <a href="https://www.predictivebrainlab.com/" target="_blank"> Predictive Brain Lab</a> at the Donders Institute (Centre for Cognitive Neuroimaging). I am co-advised by <a href="https://www.predictivebrainlab.com/people/floris-de-lange/" target="_blank"> Floris de Lange </a>, <a href="https://www.predictivebrainlab.com/people/lea-maria-schmitt/" target="_blank"> Lea-Maria Schmitt
 </a>, <a href="http://www.stefanfrank.info/" target="_blank"> Stefan Frank</a>, and  <a href="https://www.mpi.nl/people/ozyurek-asli" target="_blank"> Aslı Özyürek </a>. I also work closely with <a href="https://mtoneva.com/" target="_blank"> Mariya Toneva </a> at the Max Planck Institute for Software Systems. I am funded by an <a href="https://www.mpi.nl/department/imprs-graduate-school/13" target="_blank"> IMPRS fellowship</a>.
              <p>
My research interests lie at the intersection of machine learning, and cognive neuroscience (with a focus on language). I am particularly interested in understanding the computational and cognitive principles that underlie human multimodal percept. I mainly use computational methods to study these questions, in conjunction with data and theories from neuroscience, linguistics, and psychology.
<br> <p>  If you want to discuss any academia-related topics, please feel free to reach out to me :) 
<p> <a href="mailto:tianai DOT dong AT mpi.nl"> Email // </a> <a href="https://scholar.google.com/citations?user=AuKjLM0AAAAJ&hl=en"> Google Scholar //</a></a> <a href="https://twitter.com/DotaDong"> Twitter </a><br>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="me2.jpg"><img style="width:90%;max-width:90%" alt="profile photo" src="me2.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Papers</heading>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='merlotbrain.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/pdf/2311.07766.pdf">
                <papertitle> Multimodal Video Transformers Partially Align with Multimodal Grounding and Compositionality in the Brain</papertitle>
              </a>
              <br>
              <strong>Dota Tianai Dong</strong>,
              Mariya Toneva
              <br>
              <em><a href="https://openreview.net/forum?id=p-vL3rmYoqh">ICLR-MRL</a></em>, 2023;
              <em><a href="https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_3527860">CCN</a></em>, 2023;
              <em><a href="https://arxiv.org/pdf/2311.07766.pdf">Preprint</a></em>, 2024
              <br>
              <p> We propose to probe a pre-trained multimodal video transformer model, guided by insights from neuroscientific evidence on multimodal information processing in the human brain. </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='discogem.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://pure.mpg.de/rest/items/item_3488237/component/file_3488238/content">
                <papertitle>Discogem: A crowdsourced corpus of genre-mixed implicit discourse relations</papertitle>
              </a>
              <br>
              Merel Scholman
              <strong>Dota Tianai Dong</strong>,
              Frances Yung,
              Vera Demberg
              <br>
              <em><a href="https://pure.mpg.de/rest/items/item_3488237/component/file_3488238/content">LREC</a></em>, 2022;
              <br>
              <p>We present DiscoGeM, a crowdsourced corpus of 6,505 implicit discourse relations from three genres: political speech,
literature, and encyclopedic text.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='comparedis.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://aclanthology.org/2021.codi-main.9.pdf">
                <papertitle>Comparison of methods for explicit discourse connective identification across various domains</papertitle>
              </a>
              <br>
              Merel Scholman
              <strong>Dota Tianai Dong</strong>,
              Frances Yung,
              Vera Demberg
              <br>
              <em><a href="https://aclanthology.org/2021.codi-main.9.pdf">CODI</a></em>, 2021;
              <br>
              <p>We assess the performance on explicit
connective identification of four parse methods (PDTB e2e, Lin et al., 2014; the winner of CONLL2015, Wang and Lan, 2015; DisSent, Nie et al., 2019; and Discopy, Knaebel and Stede, 2020), along with a simple heuristic. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='orange.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://aclanthology.org/2021.splurobonlp-1.3/">
                <papertitle>Visually grounded follow-up questions: A dataset of spatial questions which require dialogue history</papertitle>
              </a>
              <br>
              <strong>Dota Tianai Dong</strong>,
              Alberto Testoni, 
              Luciana Benotti, 
              Raffaella Bernardi
              <br>
              <em><a href="https://aclanthology.org/2021.splurobonlp-1.3/">Splurobonlp</a></em>, 2021;
              <br>
              <p> We define and evaluate a methodology for extracting history-dependent spatial questions from visual dialogues.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Others</heading>
          </td>
        </tr>
      </tbody></table>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr >
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one" >
              <img src="img/prog.png" height="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://drive.google.com/file/d/1p8VNFE_wBZIHY9m9v4yxhzRV77gUg1kn/view?usp=sharing">
              <papertitle>Analyses of Multiple Discourse Relations within a Chinese Sentence</papertitle>
            </a>
            <br>
            <strong>Dota Tianai Dong</strong>, Bonnie Webber, Jennifer Spenader
            <br>
            <a href="https://drive.google.com/file/d/1p8VNFE_wBZIHY9m9v4yxhzRV77gUg1kn/view?usp=sharing">Bachelor Thesis</a>
            <p></p>
          </td>
        </tr>


        <table width="100%" cellspacing="0" cellpadding="20" border="0" align="center">
          <tbody><tr>
            <td>
              <br>
              <p align="center">
                <font size="2">
                  Template from <a href="https://github.com/jonbarron/jonbarron_website">here</a>
                </font>
              </p>
            </td></tr>
          </tbody>
        </table>

</body>

</html>
