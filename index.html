<!DOCTYPE html>
<html>
	<head>
		<title>Dota</title>
		<link rel="stylesheet" type="text/css" href="main.css">
	</head>
	<body>
		<div class="container">
    		<div class="blurb">
        		<h1>Dota - Tianai Dong</h1>
                                <p>
								<figure>
								<img src="me2.jpg " width="300" height="300" style="float:right" hspace="20">							
								</figure>
								</p>
<p>
Hi! I am a first-year PhD student, affiliated with <a href="https://www.mpi.nl/department/multimodal-language-department/23" target="_blank"> Multimodal Language Department </a> at the Max Planck Institute for Psycholinguistics, and <a href="https://www.predictivebrainlab.com/" target="_blank"> Predictive Brain Lab</a> at the Donders Institute (Centre for Cognitive Neuroimaging). I am co-advised by <a href="https://www.mpi.nl/people/ozyurek-asli" target="_blank"> Aslı Özyürek </a> , <a href="https://www.predictivebrainlab.com/people-details/floris-de-lange/" target="_blank"> Floris de Lange </a>, and <a href="http://www.stefanfrank.info/" target="_blank"> Stefan Frank</a>. I also work closely with <a href="https://mtoneva.com/" target="_blank"> Mariya Toneva </a> at the Max Planck Institute for Software Systems. I am funded by an <a href="https://www.mpi.nl/department/imprs-graduate-school/13" target="_blank"> IMPRS fellowship</a>.                  
                  
<p>My research interests lie at the intersection of computation, cognition, and language. I am particularly interested in how people understand and produce language from multimodal data (text, vision and audio) in response to naturalistic stimulation, and how these insights can be leveraged to build better artificial systems. I mainly use computational methods to study these questions, in conjunction with data and theories from neuroscience, linguistics, and psychology.<br> 

<p>  If you have questions about my work or want to discuss other academia-related topics, please feel free to reach out to me :) // <a href="mailto:tianai DOT dong AT mpi.nl"> Email // </a> <a href="https://scholar.google.com/citations?user=AuKjLM0AAAAJ&hl=en"> Google Scholar</a></a> <br>
			
                    <h2>Recent News</h2>     
  	<ul>
             <li>March 2023: I talked about "When one black box meets another" at Amazing Discoveries Stage @ InScience - International Science Film Festival.</li> 
            </ul>
  			<ul>
             <li>March 2023: Paper accepted at the first workshop on Multimodal Representation Learning (MRL) @ ICLR.</li> 
            </ul>
			<ul>
             <li>Jan 2023: I started my PhD at the Max Planck Institute for Psycholinguistics.</li> 
<br> 
            </ul>
          
            
            
        		<h2>Publications</h2>
                
                               <ul>
                               
   <li> Scholman, M.C.J., <b>Tianai, D.</b>, Yung, F., Demberg, V. <i> DiscoGeM:A Crowdsourced Corpus of Genre-Mixed Implicit Discourse Relations. </i> Proceedings of the 13th Conference on Language Resources and Evaluation (LREC 2022). <a href="http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.351.pdf" target="_blank">[paper]</a></li>
             <br>
             
             <li> Scholman, M.C.J., <b>Tianai, D.</b>, Yung, F., Demberg, V. <i> Comparison of methods for explicit discourse connective identification across various domains. </i> Proceedings of the Second Workshop on Computational Approaches to Discourse, hold in conjunction with EMNLP 2021.<a href="https://aclanthology.org/2021.codi-main.9.pdf" target="_blank">[paper]</a></li>
             <br>
             
             <li><b>Tianai, D.</b>, Testoni, A., Luciana B., Bernardi, R. <i>Visually Grounded Follow-up Questions: a Dataset of Spatial Questions Which Require Dialogue History </i> Proceedings of the Second International Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2021), hold in conjunction with ACL-IJCNLP 2021.<a href="https://aclanthology.org/2021.splurobonlp-1.3.pdf" target="_blank">[paper]</a> <a href="https://github.com/tianaidong/2021SpLU-RoboNLP-VISPA" target="_blank">[dataset]</a> <a href=https://www.youtube.com/watch?v=g34_KqPeYPs target="_blank">[talk]</a></li>
		
		
            </ul>
             	<h2>Bachelor Thesis</h2>
			<ul>
			<li><i> Analyses of Multiple Discourse Relations within a Chinese Sentence</i> <a href="https://drive.google.com/file/d/1p8VNFE_wBZIHY9m9v4yxhzRV77gUg1kn/view?usp=sharing" target="_blank">[paper]</a> Supervised by Jennifer Spenader and Bonnie Webber.
			</ul>
            
            
              </ul>
             	<h2>Miscellany</h2>
			<ul>
			<li> When not in front of a screen, I like reading, swimming, and cycling (to  <a href="https://www.heldro.nl/nijmegen/"> Heldro IJs Nijmegen</a>).</li>
            <br>
            
            <li> In my free time, I write/translate/edit articles for <a href="https://neu-reality.com/"> Neureality</a>, an NGO media for popular AI and neuroscience.</li>
			</ul>
            
    		</div><!-- /.blurb -->
		</div><!-- /.container -->
	</body>
	<footer>
		
  <p> * The photo was taken by <a href="https://it.linkedin.com/in/allisonakeith">Allison Keith</a></p>
    <p> * Last updated, April 2023</a></p>
</footer>
</html>
